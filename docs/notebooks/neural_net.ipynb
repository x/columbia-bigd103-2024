{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoNcXUfxeA8FFhQglVjWwr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Training Your First Neural Net\n","\n","In this exercise we're going to train a neural net using Pytorch.\n","\n","I've already put together a cell to do the necessary imports and fetch the training and test data."],"metadata":{"id":"mJd4uBC10VF5"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ci8_yvATlKB0","executionInfo":{"status":"ok","timestamp":1720640950549,"user_tz":240,"elapsed":2833,"user":{"displayName":"Devon Peticolas","userId":"01655597089936748753"}},"outputId":"aa2879cd-1dd6-4faa-d9b6-733c9a3aea9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 46915227.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 1618617.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 12804100.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 7517967.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","# Download training data from open datasets.\n","train_data = datasets.MNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# Download test data from open datasets.\n","test_data = datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")\n"]},{"cell_type":"markdown","source":["# 1. Setup Dataloaders\n","\n","Pytorch has a special object called a `DataLoader` which we can use to iterate through batches of `X` and `y` training and test batches.\n","\n","In neural nets, you need to choose a batch size. You calculate the loss for one batch before doing the backpropagation for that batch.\n","\n","```python\n","batch_size = ...\n","\n","# Create data loaders.\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","```\n","\n","You pick your own batch size here, but I recommend something more than 10 and less than 200.\n"],"metadata":{"id":"9B4pxauf0uGA"}},{"cell_type":"code","source":["batch_size = 128\n","\n","# Create data loaders.\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"],"metadata":{"id":"M2rcf9cc35PU","executionInfo":{"status":"ok","timestamp":1720640980233,"user_tz":240,"elapsed":193,"user":{"displayName":"Devon Peticolas","userId":"01655597089936748753"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 2. Define Your Model\n","\n","In Pytorch, we define a class to make a model. This should be largely copy-paste because the first layer _must_ be 784 (28x28) and the last layer must be 10 (10 digits), but feel free to change the hidden layer's size.\n","\n","```python\n","# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","```\n"],"metadata":{"id":"uLLbBaE7KLtf"}},{"cell_type":"code","source":["# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n"],"metadata":{"id":"rJgbzGoAKRPB","executionInfo":{"status":"ok","timestamp":1720640996646,"user_tz":240,"elapsed":171,"user":{"displayName":"Devon Peticolas","userId":"01655597089936748753"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## 3. Intialize Your Model, Loss Function, and Optimizer\n","\n","Your model needs to be initialized. Do that. Print it to inspect it.\n","\n","```python\n","model = NeuralNetwork().to(\"cpu\")\n","print(model)\n","```\n","\n","You'll also need to initialize objects for your loss function (which says how badly a batch performed) and your optimizer (which moves the weights based on the loss).\n","\n","```python\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","```"],"metadata":{"id":"6iuynlIDKRa4"}},{"cell_type":"code","source":["model = NeuralNetwork().to(\"cpu\")\n","print(model)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0v8_BKuyKYET","executionInfo":{"status":"ok","timestamp":1720641007620,"user_tz":240,"elapsed":190,"user":{"displayName":"Devon Peticolas","userId":"01655597089936748753"}},"outputId":"f3b16ab6-a242-410d-d4ae-72991eec201b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["## 4. Train Your Model\n","\n","### 4a. Scaffolding for Epochs\n","\n","One epoch is when you train your entire training dataset and then score your test dataset. You're going to do multiple epochs. Your pick as to how many (but I recommend less than 10 because it can take a while).\n","\n","Make sure you initialize your model before we begin.\n","\n","This is the rough scaffolding for the for-loop. We'll fill in the Train and Test sections in the next steps.\n","\n","```python\n","num_epochs = ...\n","for epoch in range(num_epochs):\n","    # Train model for epoch\n","    ...\n","    # Test model for epoch\n","    ...\n","\n","print(\"Model is done!\")\n","```\n","\n","### 4b. Train the Epoch\n","\n","Here's some code for training our model for one epoch. Read through it and try and make sense of it. You should be doing this exactly once per epoch _inside_ the for-loop defined in step 3.\n","\n","```python\n","# Train the model (loop over batches of training examples)\n","model.train()\n","num_training_samples = len(train_dataloader)\n","for i, (X, y) in enumerate(train_dataloader):\n","    X = X.to(\"cpu\")\n","    y = y.to(\"cpu\")\n","\n","    # Compute prediction error for the batch\n","    pred = model(X)\n","    loss = loss_fn(pred, y)\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    # Log our progress every 100 batches\n","    if i % 100 == 0:\n","        print(f\"loss: {loss.item():>7f}  [{(i+1)*len(X):>5d}/{num_training_samples:>5d}]\")\n","```\n","\n","### 4c. Test the Epoch\n","\n","Again, we test every epoch. Here's the code.\n","\n","```python\n","# Test the epoch (loop over batches of testing examples)\n","model.eval()\n","num_test_samples = len(test_dataloader)\n","total_loss = 0\n","num_correct = 0\n","with torch.no_grad():\n","    for X, y in test_dataloader:\n","        X = X.to(\"cpu\")\n","        y = y.to(\"cpu\")\n","        pred = model(X)\n","        total_loss += loss_fn(pred, y).item()\n","        num_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","# Evaluate\n","avg_loss = total_loss / num_test_samples\n","accuracy = num_correct / num_test_samples\n","print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>7f}\")\n","```\n","\n","### 4d. Train Your Model\n","\n","Train your Neural Network and track the accuracy and the loss function."],"metadata":{"id":"VIJGz-0xKYUj"}},{"cell_type":"code","source":["num_epochs = 8\n","for epoch in range(num_epochs):\n","    # Train model for epoch\n","    model.train()\n","    num_training_samples = len(train_dataloader) * batch_size\n","    for i, (X, y) in enumerate(train_dataloader):\n","        X = X.to(\"cpu\")\n","        y = y.to(\"cpu\")\n","\n","        # Compute prediction error for the batch\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        # Log our progress every 100 batches\n","        if i % 100 == 0:\n","            print(f\"loss: {loss.item():>7f}  [{(i+1)*len(X):>5d}/{num_training_samples:>5d}]\")\n","\n","    # Test the epoch (loop over batches of testing examples)\n","    model.eval()\n","    num_test_samples = len(test_dataloader) * batch_size\n","    total_loss = 0\n","    num_correct = 0\n","    with torch.no_grad():\n","        for X, y in test_dataloader:\n","            X = X.to(\"cpu\")\n","            y = y.to(\"cpu\")\n","            pred = model(X)\n","            total_loss += loss_fn(pred, y).item()\n","            num_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    # Evaluate\n","    avg_loss = total_loss / num_test_samples\n","    accuracy = num_correct / num_test_samples\n","    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>7f}\")\n","\n","\n","print(\"Model is done!\")\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djnn0XrzKsga","executionInfo":{"status":"ok","timestamp":1720641651025,"user_tz":240,"elapsed":122180,"user":{"displayName":"Devon Peticolas","userId":"01655597089936748753"}},"outputId":"4ce3d509-0c30-459d-b297-7a467c99d75e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["loss: 1.831996  [  128/60032]\n","loss: 1.874257  [12928/60032]\n","loss: 1.800290  [25728/60032]\n","loss: 1.777741  [38528/60032]\n","loss: 1.762572  [51328/60032]\n","Test Error: \n"," Accuracy: 72.3%, Avg loss: 0.013627\n","loss: 1.690844  [  128/60032]\n","loss: 1.739367  [12928/60032]\n","loss: 1.645164  [25728/60032]\n","loss: 1.625514  [38528/60032]\n","loss: 1.615918  [51328/60032]\n","Test Error: \n"," Accuracy: 73.4%, Avg loss: 0.012396\n","loss: 1.530251  [  128/60032]\n","loss: 1.583209  [12928/60032]\n","loss: 1.470782  [25728/60032]\n","loss: 1.458141  [38528/60032]\n","loss: 1.460813  [51328/60032]\n","Test Error: \n"," Accuracy: 74.7%, Avg loss: 0.011081\n","loss: 1.362254  [  128/60032]\n","loss: 1.417776  [12928/60032]\n","loss: 1.292956  [25728/60032]\n","loss: 1.291191  [38528/60032]\n","loss: 1.311737  [51328/60032]\n","Test Error: \n"," Accuracy: 76.4%, Avg loss: 0.009814\n","loss: 1.204149  [  128/60032]\n","loss: 1.259232  [12928/60032]\n","loss: 1.129884  [25728/60032]\n","loss: 1.140585  [38528/60032]\n","loss: 1.180532  [51328/60032]\n","Test Error: \n"," Accuracy: 78.1%, Avg loss: 0.008700\n","loss: 1.068506  [  128/60032]\n","loss: 1.119497  [12928/60032]\n","loss: 0.992119  [25728/60032]\n","loss: 1.014526  [38528/60032]\n","loss: 1.071596  [51328/60032]\n","Test Error: \n"," Accuracy: 79.6%, Avg loss: 0.007777\n","loss: 0.958248  [  128/60032]\n","loss: 1.002751  [12928/60032]\n","loss: 0.881005  [25728/60032]\n","loss: 0.913118  [38528/60032]\n","loss: 0.983703  [51328/60032]\n","Test Error: \n"," Accuracy: 80.4%, Avg loss: 0.007033\n","loss: 0.870459  [  128/60032]\n","loss: 0.907520  [12928/60032]\n","loss: 0.792743  [25728/60032]\n","loss: 0.832449  [38528/60032]\n","loss: 0.913139  [51328/60032]\n","Test Error: \n"," Accuracy: 81.5%, Avg loss: 0.006434\n","Model is done!\n"]}]},{"cell_type":"markdown","source":["## 5. Try Your Model on REAL IMAGES\n","\n","It only feels real if you can test it on real images.\n","\n","I pulled some of the MNIST images into our `datasets/` folder. Here's some code to test your model on them and show both the image and the model's prediction.\n","\n","```python\n","from torchvision import transforms\n","from PIL import Image\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","\n","drive.mount('/content/gdrive')\n","\n","# Define the image preprocessing steps\n","preprocess = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n","    transforms.Resize((28, 28)),  # Resize to 28x28 pixels\n","    transforms.ToTensor(),  # Convert to tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n","])\n","\n","# Set the model to eval mode\n","model.eval()\n","\n","# Loop over 10 images\n","for i in range(1, 11):\n","\n","    # Open the image\n","    img_path = f\"/content/gdrive/MyDrive/datasets/mnist_test_sample/img_{i}.jpg\"\n","    img = Image.open(img_path)\n","\n","    # Preprocess the image\n","    img_tensor = preprocess(img)\n","    img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n","\n","    # Make prediction\n","    with torch.no_grad():\n","        output = model(img_tensor)\n","        predicted_class = output.argmax(1).item()\n","\n","    # Display the image\n","    plt.figure(figsize=(2, 2))  # Set figure size to 2x2 inches\n","    plt.imshow(img, cmap=\"gray\")\n","    plt.title(\"Input Image\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # Print the prediction\n","    print(f\"Predicted class: {predicted_class}\")\n","```"],"metadata":{"id":"5p5XhquE9Q8x"}},{"cell_type":"code","source":["from torchvision import transforms\n","from PIL import Image\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","\n","drive.mount('/content/gdrive')\n","\n","# Define the image preprocessing steps\n","preprocess = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n","    transforms.Resize((28, 28)),  # Resize to 28x28 pixels\n","    transforms.ToTensor(),  # Convert to tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n","])\n","\n","# Set the model to eval mode\n","model.eval()\n","\n","# # Loop over 10 images\n","# for i in range(1, 11):\n","\n","# Open the image\n","#img_path = f\"/content/gdrive/MyDrive/datasets/mnist_test_sample/img_{i}.jpg\"\n","img_path = \"my_5.jpg\"\n","img = Image.open(img_path)\n","\n","# Preprocess the image\n","img_tensor = preprocess(img)\n","img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n","\n","# Make prediction\n","with torch.no_grad():\n","    output = model(img_tensor)\n","    print(output)\n","    predicted_class = output.argmax(1).item()\n","\n","# Display the image\n","plt.figure(figsize=(2, 2))  # Set figure size to 2x2 inches\n","plt.imshow(img, cmap=\"gray\")\n","plt.title(\"Input Image\")\n","plt.axis(\"off\")\n","plt.show()\n","\n","# Print the prediction\n","print(f\"Predicted class: {predicted_class}\")\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"zQ8pDxLJ-ncP","executionInfo":{"status":"ok","timestamp":1720641852593,"user_tz":240,"elapsed":1054,"user":{"displayName":"Devon Peticolas","userId":"01655597089936748753"}},"outputId":"008db899-fe84-422c-fef0-c51ebb503eeb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","tensor([[-0.1542,  0.3000, -0.2521,  0.1875, -0.0039,  0.2358, -0.3651,  0.4467,\n","         -0.1876, -0.0475]])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 200x200 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Predicted class: 7\n"]}]},{"cell_type":"markdown","source":["## Bonus\n","\n","If you get this far and we're still working, try changing things about your model to make the accuracy higher.\n","\n","Ideas:\n","- Change the number of epochs\n","- Change the batch size\n","- Change the size of the hidden layer\n","- Add more hidden layers\n"],"metadata":{"id":"21KkGrzIKsy1"}},{"cell_type":"code","source":[],"metadata":{"id":"Ruj8gpGE2brW"},"execution_count":null,"outputs":[]}]}